{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first_tff.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIfpzf7ltChD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e844db1-0a19-4294-8e5c-8a8744ebb83f"
      },
      "source": [
        "!pip uninstall --yes --quiet  tensorflow-federated-nightly\n",
        "!pip uninstall --yes --quiet  nest-asyncio\n",
        "!pip install  --quiet --upgrade tensorflow-federated-nightly\n",
        "!pip install  --quiet --upgrade nest-asyncio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nbclient 0.5.4 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWOpnrwltkY0",
        "outputId": "acb4e677-cce8-4d46-ae15-905f9b62dbbd"
      },
      "source": [
        "import tensorflow_federated as tff\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import collections\n",
        "import nest_asyncio\n",
        "import platform\n",
        "import time\n",
        "\n",
        "nest_asyncio.apply()\n",
        "(x, y), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# normalization\n",
        "x=tf.image.per_image_standardization(x)\n",
        "x_test=tf.image.per_image_standardization(x_test)\n",
        "\n",
        "# standardization\n",
        "# x, x_test = x / 255.0, x_test / 255.0\n",
        "print(tf.__version__)\n",
        "print(tff.__version__)\n",
        "print(platform.python_version())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.7.0-dev20210824\n",
            "0.19.0\n",
            "3.7.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8MKnNFzhsAK"
      },
      "source": [
        "NUM_CLIENTS = 100\n",
        "total_image_count = len(x)\n",
        "image_per_set = int(np.floor(total_image_count/NUM_CLIENTS))\n",
        "client_train_dataset = collections.OrderedDict()\n",
        "client_test_dataset = collections.OrderedDict()\n",
        "for i in range(1, NUM_CLIENTS+1):\n",
        "    client_name = \"client_\" + str(i)\n",
        "    start = image_per_set * (i-1)\n",
        "    end = image_per_set * i\n",
        "    data = collections.OrderedDict((('label', y[start:end]), ('pixels', x[start:end])))\n",
        "    # test_data = collections.OrderedDict((('label', y_test[start:end]), ('pixels', x_test[start:end])))\n",
        "    client_train_dataset[client_name] = data\n",
        "    # client_test_dataset[client_name]= test_data\n",
        "\n",
        "\n",
        "emnist_train = tff.simulation.datasets.TestClientData(client_train_dataset)\n",
        "# emnist_test=tff.simulation.datasets.TestClientData(client_test_dataset)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWw8qW9AuXDv"
      },
      "source": [
        "\n",
        "NUM_ROUNDS = 200\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 16\n",
        "SHUFFLE_BUFFER = 418\n",
        "PREFETCH_BUFFER = 10\n",
        "CLIENTS_PER_ROUND=5\n",
        "server_lr=1.0\n",
        "client_lr=0.01\n",
        "def preprocess(dataset):\n",
        "  def batch_format_fn(element):\n",
        "    return collections.OrderedDict(\n",
        "        x=tf.expand_dims(element['pixels'], -1), y=element['label'])\n",
        "  return dataset.map(batch_format_fn).repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n",
        "      BATCH_SIZE).prefetch(PREFETCH_BUFFER)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Jo6NczXuNPd"
      },
      "source": [
        "def create_keras_model():\n",
        "  \n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "  model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "  model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "  model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(10))\n",
        "  return model\n",
        "  \n",
        "example_dataset = emnist_train.create_tf_dataset_for_client(\n",
        "    emnist_train.client_ids[0])\n",
        "preprocessed_example_dataset = preprocess(example_dataset)\n",
        "def model_fn():\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.from_keras_model(\n",
        "      keras_model,\n",
        "    input_spec=preprocessed_example_dataset.element_spec ,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "      \n",
        "iterative_process = tff.learning.build_federated_averaging_process(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.Adam(),\n",
        "    use_experimental_simulation_loop=True\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv5lEJv-xn8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "208d7a95-65d5-4ab9-b98d-fe34bac196f5"
      },
      "source": [
        "state = iterative_process.initialize()\n",
        "start_time = time.time()\n",
        "rounds=[]\n",
        "acc=[]\n",
        "for round_num in range(1, NUM_ROUNDS):\n",
        "  sampled_clients = np.random.choice(\n",
        "    emnist_train.client_ids,\n",
        "    size=CLIENTS_PER_ROUND,\n",
        "    replace=False)\n",
        "  sampled_train_data = [\n",
        "    preprocess(emnist_train.create_tf_dataset_for_client(x))\n",
        "  for x in sampled_clients\n",
        "  ]\n",
        "  state, metrics = iterative_process.next(state, sampled_train_data)\n",
        "  rounds.append(round_num)\n",
        "  acc.append(metrics[\"train\"][\"sparse_categorical_accuracy\"])\n",
        "  print(f'Round {round_num} training loss: {round(metrics[\"train\"][\"loss\"], 5) } sparse_categorical_accuracy: {round(metrics[\"train\"][\"sparse_categorical_accuracy\"],5)}, '\n",
        "  f'time: {round((time.time()-start_time)/(round_num+1.))} secs')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:60: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:60: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Round 1 training loss: 1.5062099695205688 sparse_categorical_accuracy: 0.548799991607666, time: 26 secs\n",
            "Round 2 training loss: 0.42473000288009644 sparse_categorical_accuracy: 0.8712700009346008, time: 24 secs\n",
            "Round 3 training loss: 0.22520999610424042 sparse_categorical_accuracy: 0.9317299723625183, time: 23 secs\n",
            "Round 4 training loss: 0.16651000082492828 sparse_categorical_accuracy: 0.953000009059906, time: 23 secs\n",
            "Round 5 training loss: 0.1392900049686432 sparse_categorical_accuracy: 0.9607300162315369, time: 22 secs\n",
            "Round 6 training loss: 0.10806000232696533 sparse_categorical_accuracy: 0.9684699773788452, time: 22 secs\n",
            "Round 7 training loss: 0.10696999728679657 sparse_categorical_accuracy: 0.9670699834823608, time: 22 secs\n",
            "Round 8 training loss: 0.08603999763727188 sparse_categorical_accuracy: 0.9777299761772156, time: 22 secs\n",
            "Round 9 training loss: 0.098580002784729 sparse_categorical_accuracy: 0.9718700051307678, time: 22 secs\n",
            "Round 10 training loss: 0.07838000357151031 sparse_categorical_accuracy: 0.9764000177383423, time: 22 secs\n",
            "Round 11 training loss: 0.053289998322725296 sparse_categorical_accuracy: 0.9840700030326843, time: 22 secs\n",
            "Round 12 training loss: 0.05014000087976456 sparse_categorical_accuracy: 0.9860000014305115, time: 22 secs\n",
            "Round 13 training loss: 0.045820001512765884 sparse_categorical_accuracy: 0.988070011138916, time: 23 secs\n",
            "Round 14 training loss: 0.04295999929308891 sparse_categorical_accuracy: 0.9886699914932251, time: 23 secs\n",
            "Round 15 training loss: 0.03519999980926514 sparse_categorical_accuracy: 0.9908699989318848, time: 23 secs\n",
            "Round 16 training loss: 0.04634999856352806 sparse_categorical_accuracy: 0.9873999953269958, time: 24 secs\n",
            "Round 17 training loss: 0.05017999932169914 sparse_categorical_accuracy: 0.9858700037002563, time: 24 secs\n",
            "Round 18 training loss: 0.04385000094771385 sparse_categorical_accuracy: 0.9869999885559082, time: 24 secs\n",
            "Round 19 training loss: 0.03530000150203705 sparse_categorical_accuracy: 0.9908699989318848, time: 23 secs\n",
            "Round 20 training loss: 0.04324999824166298 sparse_categorical_accuracy: 0.988070011138916, time: 23 secs\n",
            "Round 21 training loss: 0.03288000077009201 sparse_categorical_accuracy: 0.9910699725151062, time: 23 secs\n",
            "Round 22 training loss: 0.041280001401901245 sparse_categorical_accuracy: 0.9887999892234802, time: 23 secs\n",
            "Round 23 training loss: 0.03142999857664108 sparse_categorical_accuracy: 0.9914000034332275, time: 23 secs\n",
            "Round 24 training loss: 0.03999000042676926 sparse_categorical_accuracy: 0.9888700246810913, time: 23 secs\n",
            "Round 25 training loss: 0.04115999862551689 sparse_categorical_accuracy: 0.989870011806488, time: 23 secs\n",
            "Round 26 training loss: 0.03765999898314476 sparse_categorical_accuracy: 0.9897300004959106, time: 23 secs\n",
            "Round 27 training loss: 0.030319999903440475 sparse_categorical_accuracy: 0.9925299882888794, time: 23 secs\n",
            "Round 28 training loss: 0.0370200015604496 sparse_categorical_accuracy: 0.991129994392395, time: 23 secs\n",
            "Round 29 training loss: 0.030820000916719437 sparse_categorical_accuracy: 0.9916700124740601, time: 23 secs\n",
            "Round 30 training loss: 0.02710999920964241 sparse_categorical_accuracy: 0.9926699995994568, time: 23 secs\n",
            "Round 31 training loss: 0.030789999291300774 sparse_categorical_accuracy: 0.9925299882888794, time: 22 secs\n",
            "Round 32 training loss: 0.031230000779032707 sparse_categorical_accuracy: 0.9918000102043152, time: 22 secs\n",
            "Round 33 training loss: 0.03610000014305115 sparse_categorical_accuracy: 0.9897300004959106, time: 22 secs\n",
            "Round 34 training loss: 0.03765999898314476 sparse_categorical_accuracy: 0.9906700253486633, time: 22 secs\n",
            "Round 35 training loss: 0.026100000366568565 sparse_categorical_accuracy: 0.9929999709129333, time: 22 secs\n",
            "Round 36 training loss: 0.03375000134110451 sparse_categorical_accuracy: 0.9902700185775757, time: 22 secs\n",
            "Round 37 training loss: 0.02249000035226345 sparse_categorical_accuracy: 0.9936000108718872, time: 22 secs\n",
            "Round 38 training loss: 0.027380000799894333 sparse_categorical_accuracy: 0.9925299882888794, time: 22 secs\n",
            "Round 39 training loss: 0.020190000534057617 sparse_categorical_accuracy: 0.9946699738502502, time: 22 secs\n",
            "Round 40 training loss: 0.031029999256134033 sparse_categorical_accuracy: 0.9922000169754028, time: 22 secs\n",
            "Round 41 training loss: 0.030339999124407768 sparse_categorical_accuracy: 0.9919300079345703, time: 22 secs\n",
            "Round 42 training loss: 0.01858999952673912 sparse_categorical_accuracy: 0.9951300024986267, time: 22 secs\n",
            "Round 43 training loss: 0.026170000433921814 sparse_categorical_accuracy: 0.9932000041007996, time: 22 secs\n",
            "Round 44 training loss: 0.020519999787211418 sparse_categorical_accuracy: 0.9944700002670288, time: 22 secs\n",
            "Round 45 training loss: 0.021479999646544456 sparse_categorical_accuracy: 0.9941999912261963, time: 22 secs\n",
            "Round 46 training loss: 0.023979999125003815 sparse_categorical_accuracy: 0.9942700266838074, time: 22 secs\n",
            "Round 47 training loss: 0.018810000270605087 sparse_categorical_accuracy: 0.9952700138092041, time: 22 secs\n",
            "Round 48 training loss: 0.026650000363588333 sparse_categorical_accuracy: 0.9927999973297119, time: 22 secs\n",
            "Round 49 training loss: 0.01955999992787838 sparse_categorical_accuracy: 0.9947299957275391, time: 22 secs\n",
            "Round 50 training loss: 0.0185100007802248 sparse_categorical_accuracy: 0.9944700002670288, time: 21 secs\n",
            "Round 51 training loss: 0.020349999889731407 sparse_categorical_accuracy: 0.9948700070381165, time: 21 secs\n",
            "Round 52 training loss: 0.013609999790787697 sparse_categorical_accuracy: 0.9961299896240234, time: 21 secs\n",
            "Round 53 training loss: 0.021159999072551727 sparse_categorical_accuracy: 0.9936699867248535, time: 21 secs\n",
            "Round 54 training loss: 0.018400000408291817 sparse_categorical_accuracy: 0.9952700138092041, time: 21 secs\n",
            "Round 55 training loss: 0.018120000138878822 sparse_categorical_accuracy: 0.9947299957275391, time: 21 secs\n",
            "Round 56 training loss: 0.017090000212192535 sparse_categorical_accuracy: 0.9955999851226807, time: 21 secs\n",
            "Round 57 training loss: 0.019780000671744347 sparse_categorical_accuracy: 0.9950699806213379, time: 21 secs\n",
            "Round 58 training loss: 0.01779000088572502 sparse_categorical_accuracy: 0.9956700205802917, time: 21 secs\n",
            "Round 59 training loss: 0.01157000008970499 sparse_categorical_accuracy: 0.9973300099372864, time: 21 secs\n",
            "Round 60 training loss: 0.010089999996125698 sparse_categorical_accuracy: 0.9974700212478638, time: 21 secs\n",
            "Round 61 training loss: 0.01761999912559986 sparse_categorical_accuracy: 0.9955300092697144, time: 21 secs\n",
            "Round 62 training loss: 0.01971999928355217 sparse_categorical_accuracy: 0.9947299957275391, time: 21 secs\n",
            "Round 63 training loss: 0.016100000590085983 sparse_categorical_accuracy: 0.9959999918937683, time: 21 secs\n",
            "Round 64 training loss: 0.028030000627040863 sparse_categorical_accuracy: 0.9926699995994568, time: 21 secs\n",
            "Round 65 training loss: 0.008899999782443047 sparse_categorical_accuracy: 0.9978700280189514, time: 21 secs\n",
            "Round 66 training loss: 0.015540000051259995 sparse_categorical_accuracy: 0.9965299963951111, time: 21 secs\n",
            "Round 67 training loss: 0.01768999919295311 sparse_categorical_accuracy: 0.995199978351593, time: 21 secs\n",
            "Round 68 training loss: 0.018079999834299088 sparse_categorical_accuracy: 0.9948700070381165, time: 21 secs\n",
            "Round 69 training loss: 0.01865999959409237 sparse_categorical_accuracy: 0.9955300092697144, time: 21 secs\n",
            "Round 70 training loss: 0.016429999843239784 sparse_categorical_accuracy: 0.9958699941635132, time: 21 secs\n",
            "Round 71 training loss: 0.01882999949157238 sparse_categorical_accuracy: 0.9947999715805054, time: 21 secs\n",
            "Round 72 training loss: 0.013989999890327454 sparse_categorical_accuracy: 0.9965299963951111, time: 21 secs\n",
            "Round 73 training loss: 0.01671000011265278 sparse_categorical_accuracy: 0.9954699873924255, time: 21 secs\n",
            "Round 74 training loss: 0.01425000000745058 sparse_categorical_accuracy: 0.9963300228118896, time: 21 secs\n",
            "Round 75 training loss: 0.01075000036507845 sparse_categorical_accuracy: 0.9973300099372864, time: 21 secs\n",
            "Round 76 training loss: 0.012930000200867653 sparse_categorical_accuracy: 0.9964699745178223, time: 21 secs\n",
            "Round 77 training loss: 0.011380000039935112 sparse_categorical_accuracy: 0.9973999857902527, time: 21 secs\n",
            "Round 78 training loss: 0.021150000393390656 sparse_categorical_accuracy: 0.9945999979972839, time: 21 secs\n",
            "Round 79 training loss: 0.020109999924898148 sparse_categorical_accuracy: 0.9947999715805054, time: 21 secs\n",
            "Round 80 training loss: 0.014059999957680702 sparse_categorical_accuracy: 0.9958699941635132, time: 21 secs\n",
            "Round 81 training loss: 0.011579999700188637 sparse_categorical_accuracy: 0.9965999722480774, time: 21 secs\n",
            "Round 82 training loss: 0.015809999778866768 sparse_categorical_accuracy: 0.9953299760818481, time: 21 secs\n",
            "Round 83 training loss: 0.011479999870061874 sparse_categorical_accuracy: 0.9970700144767761, time: 21 secs\n",
            "Round 84 training loss: 0.015949999913573265 sparse_categorical_accuracy: 0.9954699873924255, time: 21 secs\n",
            "Round 85 training loss: 0.012149999849498272 sparse_categorical_accuracy: 0.9968000054359436, time: 21 secs\n",
            "Round 86 training loss: 0.008340000174939632 sparse_categorical_accuracy: 0.9976699948310852, time: 21 secs\n",
            "Round 87 training loss: 0.011900000274181366 sparse_categorical_accuracy: 0.995930016040802, time: 22 secs\n",
            "Round 88 training loss: 0.014310000464320183 sparse_categorical_accuracy: 0.9960700273513794, time: 22 secs\n",
            "Round 89 training loss: 0.013150000013411045 sparse_categorical_accuracy: 0.9968000054359436, time: 22 secs\n",
            "Round 90 training loss: 0.013989999890327454 sparse_categorical_accuracy: 0.9962700009346008, time: 22 secs\n",
            "Round 91 training loss: 0.017500000074505806 sparse_categorical_accuracy: 0.9948700070381165, time: 22 secs\n",
            "Round 92 training loss: 0.011739999987185001 sparse_categorical_accuracy: 0.9968699812889099, time: 22 secs\n",
            "Round 93 training loss: 0.009770000353455544 sparse_categorical_accuracy: 0.9970700144767761, time: 22 secs\n",
            "Round 94 training loss: 0.013980000279843807 sparse_categorical_accuracy: 0.9962700009346008, time: 22 secs\n",
            "Round 95 training loss: 0.011380000039935112 sparse_categorical_accuracy: 0.9969300031661987, time: 22 secs\n",
            "Round 96 training loss: 0.010610000230371952 sparse_categorical_accuracy: 0.9973300099372864, time: 22 secs\n",
            "Round 97 training loss: 0.014419999904930592 sparse_categorical_accuracy: 0.9960700273513794, time: 22 secs\n",
            "Round 98 training loss: 0.008980000391602516 sparse_categorical_accuracy: 0.9975299835205078, time: 22 secs\n",
            "Round 99 training loss: 0.011119999922811985 sparse_categorical_accuracy: 0.9968699812889099, time: 22 secs\n",
            "Round 100 training loss: 0.012059999629855156 sparse_categorical_accuracy: 0.9963300228118896, time: 22 secs\n",
            "Round 101 training loss: 0.010590000078082085 sparse_categorical_accuracy: 0.9972000122070312, time: 22 secs\n",
            "Round 102 training loss: 0.01209999993443489 sparse_categorical_accuracy: 0.9965299963951111, time: 22 secs\n",
            "Round 103 training loss: 0.012470000423491001 sparse_categorical_accuracy: 0.9967300295829773, time: 22 secs\n",
            "Round 104 training loss: 0.014059999957680702 sparse_categorical_accuracy: 0.9964699745178223, time: 22 secs\n",
            "Round 105 training loss: 0.010710000060498714 sparse_categorical_accuracy: 0.9968699812889099, time: 22 secs\n",
            "Round 106 training loss: 0.011780000291764736 sparse_categorical_accuracy: 0.9963300228118896, time: 22 secs\n",
            "Round 107 training loss: 0.009829999879002571 sparse_categorical_accuracy: 0.9973999857902527, time: 22 secs\n",
            "Round 108 training loss: 0.012280000373721123 sparse_categorical_accuracy: 0.996399998664856, time: 22 secs\n",
            "Round 109 training loss: 0.008329999633133411 sparse_categorical_accuracy: 0.9977999925613403, time: 22 secs\n",
            "Round 110 training loss: 0.013700000010430813 sparse_categorical_accuracy: 0.9958699941635132, time: 22 secs\n",
            "Round 111 training loss: 0.01322999969124794 sparse_categorical_accuracy: 0.9958000183105469, time: 22 secs\n",
            "Round 112 training loss: 0.008209999650716782 sparse_categorical_accuracy: 0.9978700280189514, time: 22 secs\n",
            "Round 113 training loss: 0.008349999785423279 sparse_categorical_accuracy: 0.9978700280189514, time: 22 secs\n",
            "Round 114 training loss: 0.01436999998986721 sparse_categorical_accuracy: 0.9962000250816345, time: 22 secs\n",
            "Round 115 training loss: 0.010540000163018703 sparse_categorical_accuracy: 0.9971299767494202, time: 22 secs\n",
            "Round 116 training loss: 0.011090000160038471 sparse_categorical_accuracy: 0.9971299767494202, time: 22 secs\n",
            "Round 117 training loss: 0.012740000151097775 sparse_categorical_accuracy: 0.9968699812889099, time: 22 secs\n",
            "Round 118 training loss: 0.012260000221431255 sparse_categorical_accuracy: 0.996399998664856, time: 22 secs\n",
            "Round 119 training loss: 0.007470000069588423 sparse_categorical_accuracy: 0.998199999332428, time: 21 secs\n",
            "Round 120 training loss: 0.012919999659061432 sparse_categorical_accuracy: 0.9960700273513794, time: 21 secs\n",
            "Round 121 training loss: 0.009870000183582306 sparse_categorical_accuracy: 0.9968000054359436, time: 21 secs\n",
            "Round 122 training loss: 0.009739999659359455 sparse_categorical_accuracy: 0.9974700212478638, time: 21 secs\n",
            "Round 123 training loss: 0.009379999712109566 sparse_categorical_accuracy: 0.9973999857902527, time: 21 secs\n",
            "Round 124 training loss: 0.008860000409185886 sparse_categorical_accuracy: 0.9972699880599976, time: 21 secs\n",
            "Round 125 training loss: 0.008299999870359898 sparse_categorical_accuracy: 0.9979299902915955, time: 21 secs\n",
            "Round 126 training loss: 0.010739999823272228 sparse_categorical_accuracy: 0.9968000054359436, time: 21 secs\n",
            "Round 127 training loss: 0.010200000368058681 sparse_categorical_accuracy: 0.9968000054359436, time: 21 secs\n",
            "Round 128 training loss: 0.00887999963015318 sparse_categorical_accuracy: 0.9973300099372864, time: 21 secs\n",
            "Round 129 training loss: 0.008550000376999378 sparse_categorical_accuracy: 0.998199999332428, time: 21 secs\n",
            "Round 130 training loss: 0.00749000022187829 sparse_categorical_accuracy: 0.9980700016021729, time: 21 secs\n",
            "Round 131 training loss: 0.00848000030964613 sparse_categorical_accuracy: 0.9971299767494202, time: 21 secs\n",
            "Round 132 training loss: 0.01051000040024519 sparse_categorical_accuracy: 0.9968699812889099, time: 21 secs\n",
            "Round 133 training loss: 0.014379999600350857 sparse_categorical_accuracy: 0.9962700009346008, time: 21 secs\n",
            "Round 134 training loss: 0.011590000241994858 sparse_categorical_accuracy: 0.9963300228118896, time: 21 secs\n",
            "Round 135 training loss: 0.009820000268518925 sparse_categorical_accuracy: 0.9973999857902527, time: 21 secs\n",
            "Round 136 training loss: 0.011620000004768372 sparse_categorical_accuracy: 0.996999979019165, time: 21 secs\n",
            "Round 137 training loss: 0.01370999962091446 sparse_categorical_accuracy: 0.9962000250816345, time: 21 secs\n",
            "Round 138 training loss: 0.0065899998880922794 sparse_categorical_accuracy: 0.9979299902915955, time: 21 secs\n",
            "Round 139 training loss: 0.009429999627172947 sparse_categorical_accuracy: 0.9972699880599976, time: 21 secs\n",
            "Round 140 training loss: 0.015329999849200249 sparse_categorical_accuracy: 0.9961299896240234, time: 21 secs\n",
            "Round 141 training loss: 0.008100000210106373 sparse_categorical_accuracy: 0.9981300234794617, time: 21 secs\n",
            "Round 142 training loss: 0.008670000359416008 sparse_categorical_accuracy: 0.9979299902915955, time: 21 secs\n",
            "Round 143 training loss: 0.00698000006377697 sparse_categorical_accuracy: 0.9980700016021729, time: 21 secs\n",
            "Round 144 training loss: 0.008310000412166119 sparse_categorical_accuracy: 0.9976699948310852, time: 21 secs\n",
            "Round 145 training loss: 0.006730000022798777 sparse_categorical_accuracy: 0.998199999332428, time: 21 secs\n",
            "Round 146 training loss: 0.009349999949336052 sparse_categorical_accuracy: 0.9976000189781189, time: 21 secs\n",
            "Round 147 training loss: 0.01063000038266182 sparse_categorical_accuracy: 0.9967300295829773, time: 21 secs\n",
            "Round 148 training loss: 0.008620000444352627 sparse_categorical_accuracy: 0.9974700212478638, time: 21 secs\n",
            "Round 149 training loss: 0.006539999973028898 sparse_categorical_accuracy: 0.9979299902915955, time: 21 secs\n",
            "Round 150 training loss: 0.008899999782443047 sparse_categorical_accuracy: 0.9976000189781189, time: 21 secs\n",
            "Round 151 training loss: 0.005849999841302633 sparse_categorical_accuracy: 0.9982699751853943, time: 21 secs\n",
            "Round 152 training loss: 0.007780000101774931 sparse_categorical_accuracy: 0.9975299835205078, time: 21 secs\n",
            "Round 153 training loss: 0.007540000136941671 sparse_categorical_accuracy: 0.9977999925613403, time: 21 secs\n",
            "Round 154 training loss: 0.007160000037401915 sparse_categorical_accuracy: 0.997730016708374, time: 21 secs\n",
            "Round 155 training loss: 0.005929999984800816 sparse_categorical_accuracy: 0.998199999332428, time: 21 secs\n",
            "Round 156 training loss: 0.011269999668002129 sparse_categorical_accuracy: 0.996999979019165, time: 21 secs\n",
            "Round 157 training loss: 0.009200000204145908 sparse_categorical_accuracy: 0.9972699880599976, time: 21 secs\n",
            "Round 158 training loss: 0.004910000134259462 sparse_categorical_accuracy: 0.9983999729156494, time: 21 secs\n",
            "Round 159 training loss: 0.008009999990463257 sparse_categorical_accuracy: 0.997730016708374, time: 21 secs\n",
            "Round 160 training loss: 0.010320000350475311 sparse_categorical_accuracy: 0.9975299835205078, time: 21 secs\n",
            "Round 161 training loss: 0.006289999932050705 sparse_categorical_accuracy: 0.9978700280189514, time: 21 secs\n",
            "Round 162 training loss: 0.00750999990850687 sparse_categorical_accuracy: 0.9979299902915955, time: 21 secs\n",
            "Round 163 training loss: 0.011749999597668648 sparse_categorical_accuracy: 0.9968000054359436, time: 21 secs\n",
            "Round 164 training loss: 0.007770000025629997 sparse_categorical_accuracy: 0.9982699751853943, time: 21 secs\n",
            "Round 165 training loss: 0.004360000137239695 sparse_categorical_accuracy: 0.9987999796867371, time: 21 secs\n",
            "Round 166 training loss: 0.006719999946653843 sparse_categorical_accuracy: 0.998199999332428, time: 21 secs\n",
            "Round 167 training loss: 0.007780000101774931 sparse_categorical_accuracy: 0.9977999925613403, time: 21 secs\n",
            "Round 168 training loss: 0.009259999729692936 sparse_categorical_accuracy: 0.9972000122070312, time: 21 secs\n",
            "Round 169 training loss: 0.007980000227689743 sparse_categorical_accuracy: 0.9976000189781189, time: 21 secs\n",
            "Round 170 training loss: 0.01090999972075224 sparse_categorical_accuracy: 0.9972000122070312, time: 21 secs\n",
            "Round 171 training loss: 0.009800000116229057 sparse_categorical_accuracy: 0.9973999857902527, time: 21 secs\n",
            "Round 172 training loss: 0.0038900000508874655 sparse_categorical_accuracy: 0.9990699887275696, time: 21 secs\n",
            "Round 173 training loss: 0.00646999990567565 sparse_categorical_accuracy: 0.9981300234794617, time: 21 secs\n",
            "Round 174 training loss: 0.005109999794512987 sparse_categorical_accuracy: 0.9982699751853943, time: 21 secs\n",
            "Round 175 training loss: 0.007319999858736992 sparse_categorical_accuracy: 0.9980700016021729, time: 21 secs\n",
            "Round 176 training loss: 0.005630000028759241 sparse_categorical_accuracy: 0.9980700016021729, time: 21 secs\n",
            "Round 177 training loss: 0.009700000286102295 sparse_categorical_accuracy: 0.9973300099372864, time: 21 secs\n",
            "Round 178 training loss: 0.0101500004529953 sparse_categorical_accuracy: 0.9973300099372864, time: 21 secs\n",
            "Round 179 training loss: 0.009379999712109566 sparse_categorical_accuracy: 0.9974700212478638, time: 21 secs\n",
            "Round 180 training loss: 0.006659999955445528 sparse_categorical_accuracy: 0.9981300234794617, time: 21 secs\n",
            "Round 181 training loss: 0.008709999732673168 sparse_categorical_accuracy: 0.9972000122070312, time: 21 secs\n",
            "Round 182 training loss: 0.007290000095963478 sparse_categorical_accuracy: 0.9980700016021729, time: 21 secs\n",
            "Round 183 training loss: 0.0069599999114871025 sparse_categorical_accuracy: 0.997730016708374, time: 21 secs\n",
            "Round 184 training loss: 0.006730000022798777 sparse_categorical_accuracy: 0.9981300234794617, time: 21 secs\n",
            "Round 185 training loss: 0.005890000145882368 sparse_categorical_accuracy: 0.9982699751853943, time: 21 secs\n",
            "Round 186 training loss: 0.005530000198632479 sparse_categorical_accuracy: 0.9984700083732605, time: 21 secs\n",
            "Round 187 training loss: 0.008229999803006649 sparse_categorical_accuracy: 0.9976699948310852, time: 21 secs\n",
            "Round 188 training loss: 0.008609999902546406 sparse_categorical_accuracy: 0.9978700280189514, time: 21 secs\n",
            "Round 189 training loss: 0.011920000426471233 sparse_categorical_accuracy: 0.9959999918937683, time: 21 secs\n",
            "Round 190 training loss: 0.005840000230818987 sparse_categorical_accuracy: 0.9984700083732605, time: 21 secs\n",
            "Round 191 training loss: 0.006930000148713589 sparse_categorical_accuracy: 0.9981300234794617, time: 21 secs\n",
            "Round 192 training loss: 0.005890000145882368 sparse_categorical_accuracy: 0.9982699751853943, time: 21 secs\n",
            "Round 193 training loss: 0.007209999952465296 sparse_categorical_accuracy: 0.9975299835205078, time: 21 secs\n",
            "Round 194 training loss: 0.005900000222027302 sparse_categorical_accuracy: 0.9983299970626831, time: 21 secs\n",
            "Round 195 training loss: 0.005289999768137932 sparse_categorical_accuracy: 0.9983299970626831, time: 21 secs\n",
            "Round 196 training loss: 0.01056000031530857 sparse_categorical_accuracy: 0.9973300099372864, time: 21 secs\n",
            "Round 197 training loss: 0.00800000037997961 sparse_categorical_accuracy: 0.9976699948310852, time: 21 secs\n",
            "Round 198 training loss: 0.009890000335872173 sparse_categorical_accuracy: 0.9973999857902527, time: 21 secs\n",
            "Round 199 training loss: 0.008840000256896019 sparse_categorical_accuracy: 0.9975299835205078, time: 21 secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiuJr6jtk3QE"
      },
      "source": [
        "def make_federated_data(client_data, client_ids):\n",
        "  return [\n",
        "      preprocess(client_data.create_tf_dataset_for_client(x))\n",
        "      for x in client_ids\n",
        "  ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "G5acY_QxXrBm",
        "outputId": "d2474d57-a1d0-45b8-d6dc-094d074f8bac"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sampled_clients = np.random.choice(\n",
        "  emnist_train.client_ids,\n",
        "  size=CLIENTS_PER_ROUND,\n",
        "  replace=False)\n",
        "# build train data for selected clients\n",
        "\n",
        "evaluation = tff.learning.build_federated_evaluation(model_fn)\n",
        "federated_train_data= make_federated_data(emnist_train, sampled_clients)\n",
        "train_metrics = evaluation(state.model, federated_train_data)\n",
        "print(str(train_metrics))\n",
        "# federated_test_data = make_federated_data(emnist_test, sampled_clients)\n",
        "# test_metrics = evaluation(state.model, federated_test_data)\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot(rounds,acc,label='Epoch')\n",
        "# plt.legend(loc='lower right')\n",
        "plt.show()\n",
        " \n",
        "# test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "\n",
        "str(train_metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('eval', OrderedDict([('sparse_categorical_accuracy', 0.994), ('loss', 0.018559812)])), ('stat', OrderedDict([('num_examples', 15000)]))])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"OrderedDict([('eval', OrderedDict([('sparse_categorical_accuracy', 0.994), ('loss', 0.018559812)])), ('stat', OrderedDict([('num_examples', 15000)]))])\""
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp1rsXyWk4qL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}